{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"bijux-rag Documentation","text":""},{"location":"#bijux-rag-documentation","title":"bijux-rag Documentation","text":""},{"location":"#bijux-rag","title":"bijux-rag","text":"<p>At a glance: index \u2192 retrieve \u2192 ask \u2022 offline CI profile \u2022 reproducible chunk IDs + index fingerprints \u2022 CLI + FastAPI boundaries \u2022 OpenAPI drift-gated Quality: make/tox gates green (tests, lint, types, docs strict, security, SBOM, REUSE, hygiene). Everything writes to <code>artifacts/</code>. No telemetry.</p> <p> </p> <p>Docs: https://bijux.github.io/bijux-rag/ PyPI: https://pypi.org/project/bijux-rag/ Issues: https://github.com/bijux/bijux-rag/issues Changelog: https://bijux.github.io/bijux-rag/changelog/</p> <p>bijux-rag is a standalone Retrieval-Augmented Generation (RAG) toolkit for Python, emphasizing a functional core with pure transformations for document processing, chunking, and retrieval. It isolates I/O through explicit adapters and effect descriptions, enabling composable, testable pipelines without dependency on external frameworks. The toolkit supports both synchronous and asynchronous operations, with a focus on resilience, type safety, and interoperability.</p> <p>All quality gates\u2014enforced via Tox and Make\u2014remain green: comprehensive tests (unit, integration, end-to-end), static analysis (linting, typing with MyPy/Pyright/Pytype), security audits (Bandit, Pip-Audit), and builds. Coverage is gated at 90%+ on the pinned eval suite; the codebase adheres to REUSE licensing standards and ships full MkDocs documentation.</p>"},{"location":"#at-a-glance","title":"At a Glance","text":"<ul> <li>Core Philosophy: Functional programming principles for RAG\u2014pure functions, immutable data structures (e.g., document trees), and explicit effects via <code>IOPlan</code>/<code>AsyncPlan</code>\u2014to ensure determinism and ease of testing.</li> <li>Key Components: Primitives for chunking (fixed-size, recursive), embedding pipelines, result folding (fail-fast, error collection), and streaming (bounded concurrency, rate limiting).</li> <li>Resilience Features: Policy-driven retries (with exponential backoff and jitter), timeouts, transactions, and fakes for testing (clocks, sleepers).</li> <li>Interfaces: CLI for batch processing, HTTP API via FastAPI for serving, and Python API for custom pipelines.</li> <li>Dependencies: Minimal runtime (Pydantic, NumPy, FastAPI, Uvicorn); dev extras for testing (Pytest, Hypothesis) and docs (MkDocs).</li> <li>Version &amp; Compatibility: v0.1.0; Python 3.11\u20133.13; MIT-licensed.</li> <li>Quality Metrics: 100% coverage; strict typing; security-scanned; REUSE-compliant.</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Features</li> <li>Installation</li> <li>Quick Start</li> <li>Usage</li> <li>Architecture</li> <li>Testing and Quality</li> <li>Contributing</li> <li>License</li> <li>Acknowledgments</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"#features","title":"Features","text":"<p>bijux-rag prioritizes modularity and purity, allowing users to build RAG systems from composable building blocks while maintaining control over effects and dependencies.</p> <ul> <li>Functional Primitives: Pure functions for document tree manipulation (flattening, folding), result handling (<code>Result[T, ErrInfo]</code> monad with folds like fail-fast or error-capped), and iterator-based pipelines.</li> <li>Effect Management: Deferred I/O via <code>IOPlan</code> (sync) and <code>AsyncPlan</code> (async), supporting retries, transactions, backpressure, and rate limiting as configurable policies.</li> <li>Resilience and Testing: Built-in policies for transient error handling; test utilities like fake clocks and sleepers ensure reliable unit testing without mocks.</li> <li>Adapters and Interop: Storage options (file, in-memory); compatibility with NumPy for vectors, Pydantic for validation, and standard libraries (e.g., <code>itertools</code>, <code>functools</code>).</li> <li>Streaming Capabilities: Lazy async streams with bounded mapping, fair merging, and chunking policies for high-throughput scenarios.</li> <li>Tooling Integration: Comprehensive setup with Ruff for style, multiple type checkers, Hypothesis for property-based tests, and MkDocs for documentation.</li> </ul> <p>\u2191 Back to Top</p>"},{"location":"#installation","title":"Installation","text":"<p>Requires Python 3.11 or later.</p> <pre><code>pip install bijux-rag\n</code></pre> <p>For development (includes testing, documentation, and linting tools):</p> <pre><code>pip install bijux-rag[dev]\n</code></pre> <p>From source:</p> <pre><code>git clone https://github.com/bijux/bijux-rag.git\ncd bijux-rag\nmake bootstrap  # Sets up virtualenv and installs in editable mode\n</code></pre> <p>Dependencies are minimal and security-audited; refer to <code>pyproject.toml</code> for details.</p> <p>\u2191 Back to Top</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Process documents via CLI:</p> <pre><code>bijux-rag process --input docs.csv --output embeddings.msgpack\n</code></pre> <p>This command reads CSV documents, applies functional chunking, performs embedding (via configured adapter), and outputs MessagePack results.</p> <p>Programmatic equivalent:</p> <pre><code>from bijux_rag.core.rag_types import RawDoc\nfrom bijux_rag.pipelines.embedding import embed_docs\nfrom bijux_rag.infra.adapters.memory_storage import InMemoryStorage\n\ndocs = [RawDoc(doc_id=\"1\", title=\"Example\", abstract=\"Sample text.\")]\nstorage = InMemoryStorage()\nresults = list(embed_docs(docs, storage))  # Composable iterator pipeline\n</code></pre> <p>\u2191 Back to Top</p>"},{"location":"#usage","title":"Usage","text":"<p>bijux-rag offers multiple entry points: CLI for scripting, HTTP API for services, and Python API for integration.</p>"},{"location":"#cli","title":"CLI","text":"<p>Access help:</p> <pre><code>bijux-rag --help\n</code></pre> <p>Example with custom parameters:</p> <pre><code>bijux-rag process --input input.csv --chunk-size 512 --embedder default\n</code></pre> <p>Note: Embedder options depend on configured adapters; defaults to basic implementations.</p>"},{"location":"#http-api","title":"HTTP API","text":"<p>Launch the server:</p> <pre><code>bijux-rag serve --port 8000\n</code></pre> <p>Interact via endpoints like <code>/embed</code> (POST documents for processing) or <code>/retrieve</code> (query-based retrieval). Explore via OpenAPI at <code>/docs</code>.</p>"},{"location":"#python-api","title":"Python API","text":"<p>Focuses on composability:</p> <ul> <li>Documents: Use <code>RawDoc</code> and <code>Chunk</code> types; build trees with <code>make_chunk</code>.</li> <li>Pipelines: Chain functions, e.g., <code>read_docs | fixed_size_chunk | embed_docs</code>.</li> <li>Effects: Wrap I/O in <code>IOPlan</code> for sync or <code>AsyncPlan</code> for async; apply policies like <code>retry_idempotent</code>.</li> <li>Streaming: Leverage <code>AsyncGen</code> for lazy processing, e.g., <code>async_gen_bounded_map</code> for concurrency control.</li> </ul> <p>Synchronous retry example:</p> <pre><code>from bijux_rag.domain.effects import retry_idempotent, RetryPolicy\nfrom bijux_rag.policies.chunking import fixed_size_chunk\nfrom bijux_rag.result import fold_results_fail_fast\n\npolicy = RetryPolicy(max_attempts=3)\nsafe_read = retry_idempotent(policy)(storage.read_docs(\"input.csv\"))\ndocs_results = list(safe_read(\"input.csv\"))\nchunks = list(fold_results_fail_fast(docs_results, [], fixed_size_chunk))\n</code></pre> <p>Asynchronous streaming example:</p> <pre><code>from bijux_rag.domain.effects.async_ import async_gen_map, resilient_mapper\n\nmapper = resilient_mapper(embed_fn, RetryPolicy(max_attempts=3))\nstream = async_gen_map(source_stream, mapper)\nasync for result in stream():\n    # Handle result\n</code></pre> <p>Consult the API reference in documentation for complete details.</p> <p>\u2191 Back to Top</p>"},{"location":"#architecture","title":"Architecture","text":"<p>Adopts a hexagonal (ports and adapters) design with a functional core:</p> <ul> <li>Boundaries: CLI and HTTP shells interpret inputs and delegate to domain logic.</li> <li>Core: Pure, deterministic functions for RAG operations (e.g., tree folding, result monads).</li> <li>Domain: Effect descriptions (<code>IOPlan</code>, <code>AsyncPlan</code>), policies (chunking, retry), and types.</li> <li>Infra: Pluggable adapters for storage (file, memory) and other I/O.</li> <li>Interop/Policies: Helpers for stdlib FP and reusable behaviors.</li> </ul> <p>This structure facilitates adapter swaps (e.g., local to cloud storage) without altering core code. Review Architecture Documentation for decision records (ADRs) and overviews.</p> <p>\u2191 Back to Top</p>"},{"location":"#testing-and-quality","title":"Testing and Quality","text":"<p>Execute tests:</p> <pre><code>make test\n</code></pre> <p>Other targets:</p> <ul> <li><code>make lint</code>: Enforces style (Ruff) and types (MyPy, Pyright, Pytype).</li> <li><code>make security</code>: Runs Bandit and dependency audits.</li> <li><code>make docs</code>: Builds and serves MkDocs.</li> <li><code>make all</code>: Comprehensive run (clean, install, test, lint, build).</li> </ul> <p>CI ensures all gates pass on every commit.</p> <p>\u2191 Back to Top</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Report issues or suggest features via GitHub Issues. Pull requests must maintain green gates. Setup instructions:</p> <pre><code>make bootstrap\n</code></pre> <p>Follow guidelines in CONTRIBUTING.md.</p> <p>\u2191 Back to Top</p>"},{"location":"#license","title":"License","text":"<p>MIT License\u2014see LICENSE. The project is fully REUSE-compliant for copyright and licensing metadata.</p> <p>\u2191 Back to Top</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>Draws inspiration from functional programming paradigms (e.g., monads, immutability) and RAG literature. Gratitude to open-source tools like Ruff, Hypothesis, and MkDocs that support the project's quality standards.</p> <p>\u2191 Back to Top</p>"},{"location":"USAGE/","title":"Usage","text":""},{"location":"USAGE/#usage","title":"Usage","text":""},{"location":"USAGE/#usage_1","title":"Usage","text":""},{"location":"USAGE/#cli","title":"CLI","text":"<p>Process documents, build indexes, retrieve, and ask via the CLI:</p> <pre><code># Ingest and chunk CSV docs (outputs msgpack chunks)\nbijux-rag process --input data/arxiv_cs_abstracts_10k.csv --output artifacts/chunks.msgpack --chunk-size 512\n\n# Build index from chunks (BM25 or vector)\nbijux-rag index-build --input artifacts/chunks.msgpack --output artifacts/index.msgpack --backend bm25\n\n# Retrieve top-k matches\nbijux-rag retrieve --index artifacts/index.msgpack --query \"functional programming in RAG\" --top-k 10\n\n# Ask with grounded response (citations from retrieved)\nbijux-rag ask --index artifacts/index.msgpack --query \"explain RAG effects\" --top-k 5 --format json\n\n# Run eval suite (pinned corpus/queries)\nbijux-rag eval --suite tests/eval --index artifacts/index.msgpack\n</code></pre> <ul> <li><code>--backend bm25|numpy-cosine</code> (deterministic profiles).</li> <li><code>--embedder default|custom</code> for vector indexes.</li> <li><code>--filter key=value</code> for metadata filtering (AND).</li> <li>See <code>bijux-rag --help</code> for full options.</li> </ul>"},{"location":"USAGE/#library","title":"Library","text":"<p>Build composable RAG pipelines programmatically:</p> <pre><code>from bijux_rag.core.rag_types import RawDoc\nfrom bijux_rag.domain.effects.async_ import async_gen_from_list, async_gen_map\nfrom bijux_rag.policies.chunking import fixed_size_chunk\nfrom bijux_rag.pipelines.embedding import embed_docs\nfrom bijux_rag.rag.app import RagApp\nfrom bijux_rag.result.types import unwrap\n\ndocs = [RawDoc(doc_id=\"1\", title=\"RAG Intro\", abstract=\"Retrieval-Augmented Generation combines search and LLMs.\")]\nchunks = list(async_gen_map(async_gen_from_list(docs), fixed_size_chunk))  # Streaming chunking\nembedded = list(embed_docs(chunks))  # Embed pipeline\n\napp = RagApp()  # Configurable app\nindex = app.build_index(embedded, backend=\"bm25\").unwrap()\nretrieved = app.retrieve(index, query=\"what is RAG?\", top_k=5).unwrap()\nanswer = app.ask(index, query=\"explain RAG\", top_k=5, rerank=True).unwrap()[\"answer\"]\nprint(answer)\n</code></pre> <p>Leverage effects for resilience: wrap in <code>retry_idempotent</code> or <code>async_with_resilience</code>.</p>"},{"location":"USAGE/#api-fastapi","title":"API (FastAPI)","text":"<p>Launch the HTTP server:</p> <pre><code>uvicorn bijux_rag.boundaries.web.fastapi_app:app --host 0.0.0.0 --port 8000 --reload\n</code></pre> <p>Endpoints (v1 prefix): - <code>GET /health</code> \u2192 <code>{\"status\": \"ok\"}</code> - <code>POST /index/build</code> (JSON docs array, backend, chunk params) \u2192 index ID. - <code>POST /retrieve</code> (index_id, query, filters?, top_k) \u2192 ranked results. - <code>POST /ask</code> (index_id, query, top_k, rerank?) \u2192 grounded answer with citations. - <code>POST /chunks</code> (docs, chunk_size, overlap) \u2192 chunked output.</p> <p>Full schema in docs/reference/http_api.md (OpenAPI compliant).</p>"},{"location":"artifacts/","title":"Artifacts &amp; Outputs","text":""},{"location":"artifacts/#artifacts-outputs","title":"Artifacts &amp; Outputs","text":"<p>All tooling writes under <code>artifacts/</code> to maintain zero root pollution. Key locations:</p> <ul> <li><code>artifacts/test/</code>: pytest caches, coverage (<code>.coverage</code>, <code>coverage.xml</code>, <code>htmlcov/</code>), junit XML.</li> <li><code>artifacts/lint/</code>: ruff/mypy/pyright/pytype reports.</li> <li><code>artifacts/api/</code>: OpenAPI drift output, schemathesis logs.</li> <li><code>artifacts/docs/</code>: mkdocs site output (when using docs targets).</li> <li><code>artifacts/security/</code>: bandit and pip-audit reports.</li> <li><code>artifacts/sbom/</code>: SBOM outputs.</li> </ul> <p>If you see cache or report files at repository root, run <code>make hygiene</code> and fix the offender before committing.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#changelog_1","title":"Changelog","text":"<p>All notable changes to bijux-rag are documented here. This project adheres to Semantic Versioning and the Keep a Changelog format.</p>"},{"location":"changelog/#010-2025-12-26","title":"[0.1.0] \u2013 2025-12-26","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Core and Functional Primitives: Added RAG types (<code>RawDoc</code>, <code>Chunk</code>), result monad (<code>Result[T, ErrInfo]</code> with monadic operations and folds like <code>fold_results_fail_fast</code>), immutable document trees via <code>make_chunk</code>, and tree utilities (<code>flatten</code>, <code>fold_tree</code>) with stack-safety.</li> <li>Effect Descriptions: Introduced <code>IOPlan</code> for deferred sync I/O (<code>io_pure</code>, <code>io_bind</code>, <code>perform</code>), retry wrappers (<code>retry_idempotent</code> with <code>RetryPolicy</code>), and transaction bracketing (<code>Session</code>, <code>Tx</code>, <code>with_tx</code>).</li> <li>Async Effects and Streams: Defined <code>AsyncPlan</code>/<code>AsyncGen</code> for async operations (<code>async_pure</code>, <code>async_bind</code>, <code>async_gather</code>, <code>async_gen_map</code>, <code>async_gen_flat_map</code>, <code>async_gen_gather</code>), with lifts for sync integration (<code>lift_sync</code>, <code>lift_sync_with_executor</code>).</li> <li>Resilience and Policies: Added async policies for retries (<code>AsyncRetryPolicy</code>), timeouts (<code>TimeoutPolicy</code>), backpressure (<code>BackpressurePolicy</code>), rate limiting (<code>RateLimitPolicy</code>), fairness (<code>FairnessPolicy</code>), and chunking (<code>ChunkPolicy</code>); included test fakes (<code>FakeClock</code>, <code>FakeSleeper</code>, <code>ResilienceEnv</code>).</li> <li>Streaming Combinators: Provided bounded mapping (<code>async_gen_bounded_map</code>), rate limiting (<code>async_gen_rate_limited</code>), fair merging (<code>async_gen_fair_merge</code>), and chunking (<code>async_gen_chunk</code>); added streaming maps (<code>try_map_iter</code>, <code>par_try_map_iter</code>).</li> <li>Interop and Helpers: Included stdlib FP utilities (<code>merge_streams</code>, <code>running_sum</code>) and Toolz-compatible functions (<code>compose</code>, <code>curried_map</code>, <code>reduceby</code>); added chunking policies (<code>fixed_size_chunk</code>).</li> <li>Adapters and Pipelines: Implemented storage adapters (<code>FileStorage</code>, <code>InMemoryStorage</code>) with CSV support; defined composable pipelines like <code>embed_docs</code>.</li> <li>Boundaries and APIs: Added CLI entrypoint (<code>bijux-rag</code>) for processing/serving; FastAPI HTTP API with embedding/retrieval endpoints and OpenAPI schema.</li> <li>Typing and Testing: Included <code>py.typed</code> markers, msgpack stubs, and strict configs for MyPy/Pyright/Pytype; comprehensive tests with Hypothesis (laws, equivalence), coverage, and E2E markers.</li> <li>Documentation and Tooling: MkDocs setup with Material theme, plugins (mkdocstrings, minify), and pages for overview, usage, API reference, architecture (ADRs), and changelog.</li> <li>Quality Pipeline: Linting (Ruff), code health (Vulture, Deptry, Interrogate), security (Bandit, Pip-Audit), modular Makefiles (test, lint, docs, build), Tox envs (3.11-3.13), and CI with GitHub Actions.</li> <li>Build and Compliance: Hatchling packaging with VCS versioning; SBOM (CycloneDX), citations (CFF, BibTeX); REUSE compliance with MIT/CC0 licenses.</li> </ul> <p>Back to top</p>"},{"location":"community/","title":"Community &amp; Contributions","text":""},{"location":"community/#community-contributions","title":"Community &amp; Contributions","text":"<ul> <li>See CONTRIBUTING for workflow, branching, and review expectations.</li> <li>See CODE_OF_CONDUCT for expected behavior.</li> <li>Security issues? Follow the SECURITY policy.</li> </ul> <p>We welcome reproducible bug reports, small focused pull requests, and documentation improvements aligned with the bijux-cli standards.</p>"},{"location":"project_overview/","title":"Project Overview","text":""},{"location":"project_overview/#project-overview","title":"Project Overview","text":"<p>This page surfaces the high-level structure and workflows for bijux-rag. For a quick tree view, see the embedded project layout below.</p>"},{"location":"project_overview/#project-tree-guide","title":"Project Tree &amp; Guide","text":"<p>Quick map of the bijux-rag repository (aligned with the bijux-cli documentation style).</p>"},{"location":"project_overview/#top-level-layout","title":"Top-Level Layout","text":"<pre><code>.\n\u251c\u2500\u2500 .github/workflows/   # CI/CD (ci, deploy-docs, publish)\n\u251c\u2500\u2500 config/              # lint/type/security configs (coveragerc, mypy, pyright, pytype, ruff)\n\u251c\u2500\u2500 data/                # sample datasets (arxiv abstracts CSV)\n\u251c\u2500\u2500 docs/                # MkDocs sources (includes ADRs and reference pages)\n\u251c\u2500\u2500 makefiles/           # Makefile modules (api, build, citation, docs, hygiene, lint, publish, quality, sbom, security, test)\n\u251c\u2500\u2500 scripts/             # helper scripts (download_data, openapi_drift)\n\u251c\u2500\u2500 src/bijux_rag/       # library code (functional core + boundaries + effects)\n\u251c\u2500\u2500 tests/               # unit + e2e + strategies + eval assets\n\u251c\u2500\u2500 typings/             # custom stubs (msgpack)\n\u251c\u2500\u2500 .gitignore           # git ignores\n\u251c\u2500\u2500 CHANGELOG.md         # version history\n\u251c\u2500\u2500 CITATION.cff         # citation metadata\n\u251c\u2500\u2500 CODE_OF_CONDUCT.md   # community guidelines\n\u251c\u2500\u2500 CONTRIBUTING.md      # contributor guide\n\u251c\u2500\u2500 LICENSE              # MIT license\n\u251c\u2500\u2500 LICENSES/            # full texts (CC0-1.0, MIT)\n\u251c\u2500\u2500 Makefile             # main Makefile entrypoint\n\u251c\u2500\u2500 PROJECT_TREE.md      # this file\n\u251c\u2500\u2500 README.md            # project overview\n\u251c\u2500\u2500 REUSE.toml           # REUSE annotations\n\u251c\u2500\u2500 SECURITY.md          # security policy\n\u251c\u2500\u2500 TESTS.md             # tests overview\n\u251c\u2500\u2500 TOOLING.md           # tooling guide\n\u251c\u2500\u2500 USAGE.md             # usage instructions\n\u251c\u2500\u2500 mkdocs.yml           # MkDocs config\n\u251c\u2500\u2500 package.json         # Node deps (for Pyright)\n\u251c\u2500\u2500 pyproject.toml       # Hatchling build + deps\n\u251c\u2500\u2500 pytest.ini           # pytest config\n\u251c\u2500\u2500 tox.ini              # tox envs\n\u2514\u2500\u2500 artifacts/           # generated outputs (test coverage, lint reports, docs site, sbom, etc.)\n</code></pre>"},{"location":"project_overview/#source-code-high-level","title":"Source Code (high level)","text":"<ul> <li><code>src/bijux_rag/boundaries/</code> \u2014 shells and adapters (CLI via typer_cli/rag_main, HTTP via fastapi_app/rag_api_shell, exception_bridge, pydantic_edges, serde).</li> <li><code>src/bijux_rag/core/</code> \u2014 shared RAG types (rag_types), structural dedup, rules (DSL/lint/pred).</li> <li><code>src/bijux_rag/domain/</code> \u2014 effects and capabilities (async_ with concurrency/plan/resilience/stream, io_plan, io_retry, tx; facades, idempotent, logging, composition).</li> <li><code>src/bijux_rag/fp/</code> \u2014 functional primitives (core with chunk/state_machine, effects like reader/state/writer, laws, applicative/functor/monoid/option_result/validation).</li> <li><code>src/bijux_rag/infra/adapters/</code> \u2014 pluggable impls (async_runtime, atomic_storage, clock, file_storage, logger, memory_storage).</li> <li><code>src/bijux_rag/interop/</code> \u2014 compat layers (dataframes, returns_compat, stdlib_fp, toolz_compat).</li> <li><code>src/bijux_rag/pipelines/</code> \u2014 composable pipelines (cli, configured, distributed, specs).</li> <li><code>src/bijux_rag/policies/</code> \u2014 reusable behaviors (breakers, memo, reports, resources, retries).</li> <li><code>src/bijux_rag/rag/</code> \u2014 core RAG domain (app, chunking, clean_cfg/config, core, domain with chunk/embedding/metadata/perf/text, embedders, generators, indexes, ports, rag_api, rerankers, stages, stdlib_fp, streaming_rag, types).</li> <li><code>src/bijux_rag/result/</code> \u2014 result monad (folds, stream, types).</li> <li><code>src/bijux_rag/streaming/</code> \u2014 streaming utils (compose, contiguity, fanin/fanout, observability, sampling, time, types).</li> <li><code>src/bijux_rag/tree/</code> \u2014 tree operations (_traversal, folds).</li> </ul>"},{"location":"project_overview/#tests-eval","title":"Tests &amp; Eval","text":"<ul> <li><code>tests/unit/</code> \u2014 focused units and property tests (boundaries/adapters, domain async/io/retry/session, fp laws/core/iter/pattern, infra adapters, interop, pipelines, policies, rag domain/api/stages, result option/folds/stream, streaming, tree flatten/folds).</li> <li><code>tests/e2e/</code> \u2014 end-to-end smoke/gates (cli_smoke, eval_suite, rag_truthfulness_gate, real_rag_smoke) with fixtures.</li> <li><code>tests/eval/</code> \u2014 pinned corpus/queries JSONL with licenses.</li> <li><code>tests/strategies.py</code> \u2014 Hypothesis strategies for trees/chains/results.</li> <li><code>tests/helpers.py</code> \u2014 test utils.</li> <li><code>tests/conftest.py</code> \u2014 global fixtures.</li> </ul>"},{"location":"project_overview/#docs","title":"Docs","text":"<ul> <li><code>docs/index.md</code> \u2014 front door (embeds README).</li> <li><code>docs/project_overview.md</code> \u2014 overview and tree (this content embedded via MkDocs).</li> <li><code>docs/reference/</code> \u2014 API docs (cli.md, http_api.md, python.md via mkdocstrings).</li> <li><code>docs/architecture/</code> \u2014 overview (index.md) + ADRs (adr/index.md).</li> <li><code>docs/ADR/</code> \u2014 individual ADRs (0003-docstring-style, 0004-linting-quality, 0005-zero-pollution).</li> <li><code>docs/artifacts.md</code> \u2014 artifact dir explanations.</li> <li><code>docs/assets/</code> \u2014 images (bijux_icon/logo).</li> <li><code>docs/community.md</code>, <code>docs/changelog.md</code>, <code>docs/tests.md</code>, <code>docs/tooling.md</code>, <code>docs/usage.md</code> \u2014 additional guides.</li> </ul>"},{"location":"project_overview/#config-tooling","title":"Config &amp; Tooling","text":"<ul> <li><code>pyproject.toml</code> \u2014 Hatchling build, deps, scripts, classifiers.</li> <li><code>tox.ini</code> \u2014 multi-Python envs mirroring make targets.</li> <li><code>pytest.ini</code> \u2014 pytest config (paths, markers, asyncio, timeouts).</li> <li><code>mkdocs.yml</code> \u2014 MkDocs setup (theme, plugins, nav, extensions).</li> <li><code>config/coveragerc.ini</code> \u2014 coverage omit/includes.</li> <li><code>config/mypy.ini</code> \u2014 mypy strict settings.</li> <li><code>config/pyrightconfig.json</code> \u2014 pyright includes/excludes.</li> <li><code>config/pytype.cfg</code> \u2014 pytype inputs/excludes.</li> <li><code>config/ruff.toml</code> \u2014 ruff line-length/target-version/selects.</li> <li><code>Makefile</code> + <code>makefiles/</code> \u2014 entrypoints (<code>make test</code>, <code>make lint</code>, <code>make quality</code>, <code>make security</code>, <code>make api</code>, <code>make docs</code>, <code>make build</code>, <code>make sbom</code>, <code>make citation</code>, <code>make hygiene</code>, <code>make all</code>).</li> <li><code>scripts/download_data.sh</code> \u2014 data fetcher.</li> <li><code>scripts/openapi_drift.py</code> \u2014 API schema drift checker.</li> </ul>"},{"location":"project_overview/#policies-governance","title":"Policies &amp; Governance","text":"<ul> <li><code>CHANGELOG.md</code> \u2014 version history (Keep a Changelog format).</li> <li><code>CITATION.cff</code> \u2014 citation metadata.</li> <li><code>CODE_OF_CONDUCT.md</code> \u2014 Contributor Covenant.</li> <li><code>CONTRIBUTING.md</code> \u2014 setup/workflow/PR guide.</li> <li><code>SECURITY.md</code> \u2014 vulnerability reporting.</li> <li><code>REUSE.toml</code> \u2014 license annotations (CC0 for assets, MIT for code/docs).</li> <li><code>LICENSE</code>, <code>LICENSES/</code> \u2014 MIT + CC0 texts.</li> </ul> <p>Back to top</p>"},{"location":"tests/","title":"Tests","text":""},{"location":"tests/#tests","title":"Tests","text":""},{"location":"tests/#tests-eval","title":"Tests &amp; Eval","text":"<ul> <li>Unit/Property: <code>make test</code> runs unit + property-based suites with coverage to <code>artifacts/test</code>.</li> <li>E2E quality gates: 25 pinned queries \u00d7 4 assertions (100 tests) exercising index\u2192retrieve\u2192ask deterministically.</li> <li>Eval assets: <code>tests/eval/corpus.jsonl</code>, <code>tests/eval/queries.jsonl</code>, plus baselines under <code>tests/eval/baselines/</code>.</li> <li>Baselines: generated via <code>make eval-baseline</code> (BM25 CI profile); CI gates regressions via recall/MRR/nDCG and grounding checks.</li> <li>API fuzz: <code>make api</code> runs Schemathesis against <code>api/v1/schema.yaml</code>.</li> <li>Artifacts: coverage XML/HTML in <code>artifacts/test</code>, junit in <code>artifacts/test/junit.xml</code>.</li> </ul>"},{"location":"tooling/","title":"Tooling","text":""},{"location":"tooling/#tooling","title":"Tooling","text":""},{"location":"tooling/#tooling-make-targets","title":"Tooling &amp; Make targets","text":"<p>Front-door commands (mirrors bijux-cli):</p> <ul> <li><code>make fmt</code> \u2014 ruff format + autofix</li> <li><code>make lint</code> \u2014 ruff check + mypy + pyright (artifacts in <code>artifacts/lint</code>)</li> <li><code>make type</code> \u2014 pyright (also run via <code>make lint</code>)</li> <li><code>make test</code> \u2014 unit + e2e + coverage (artifacts/test)</li> <li><code>make api</code> \u2014 OpenAPI lint + drift + Schemathesis</li> <li><code>make docs</code> \u2014 mkdocs build (strict) \u2192 <code>artifacts/docs/site</code></li> <li><code>make quality</code> \u2014 vulture/deptry/reuse/interrogate</li> <li><code>make security</code> \u2014 bandit + pip-audit (gating)</li> <li><code>make sbom</code> \u2014 CycloneDX SBOMs</li> <li><code>make hygiene</code> \u2014 zero-root-pollution gate</li> <li><code>make all</code> \u2014 clean \u2192 install \u2192 test \u2192 lint \u2192 quality \u2192 security \u2192 api \u2192 docs \u2192 build \u2192 sbom \u2192 citation \u2192 hygiene</li> </ul> <p>All caches and artifacts are redirected under <code>artifacts/</code> to keep the repo root clean.</p>"},{"location":"ADR/","title":"ADR","text":""},{"location":"ADR/#top","title":"Architecture Decision Records","text":"<ul> <li>ADR 0003: Docstring And Documentation Style</li> <li>ADR 0004: Linting Quality Security</li> <li>ADR 0005: Zero-Root-Pollution \u2014 Artifacts Only</li> </ul>"},{"location":"ADR/0003-docstring-and-documentation-style/","title":"ADR-0003: Docstring and Documentation Style","text":""},{"location":"ADR/0003-docstring-and-documentation-style/#adr-0003-docstring-and-documentation-style","title":"ADR-0003: Docstring and Documentation Style","text":"<ul> <li>Date: 2025-08-01  </li> <li>Status: Accepted  </li> <li>Author: Bijan Mousavi  </li> </ul>"},{"location":"ADR/0003-docstring-and-documentation-style/#context","title":"Context","text":"<p>Our codebase demands a rigorously consistent and machine-parsable documentation style to facilitate the seamless, automated generation of comprehensive and visually appealing webpages through MkDocs. This process depends entirely on full, detailed docstrings placed at the top of every Python file, which must thoroughly explain the complete contents of that file. User-facing documentation\u2014encompassing guides, ADRs, and READMEs\u2014must remain highly readable in plain text while rendering flawlessly on the web. By utilizing tools like MkDocs for rendering and linters for validation, we enable all contributors to produce and sustain uniformly high-quality documentation, with absolutely no exceptions permitted.</p>"},{"location":"ADR/0003-docstring-and-documentation-style/#decision","title":"Decision","text":""},{"location":"ADR/0003-docstring-and-documentation-style/#docstrings","title":"Docstrings","text":"<p>We enforce the exclusive use of the Google Python Style Guide for all in-code docstrings throughout the codebase, prohibiting any deviations or mixed styles to guarantee absolute unification and automated enforcement.</p> <ul> <li>Every Python file must commence with a comprehensive module-level docstring enclosed in triple quotes <code>\"\"\"\u2026\"\"\"</code>, beginning with a concise one-sentence summary on the initial line.</li> <li>After the summary, insert a blank line followed by an exhaustive description of the file's entire code, covering its overall purpose, architectural structure, primary components, interdependencies, and pertinent usage guidelines. This docstring must be fully self-explanatory, eschewing abbreviated or partial content.</li> <li> <p>Include the following sections in precise order, omitting only those that are wholly inapplicable:</p> <ul> <li>Args: <pre><code> Args:\n     name (str): Description of the argument.\n     count (int): Description of the argument.\n</code></pre></li> <li>Returns: <pre><code>Returns:\n    bool: Description of the return value.\n</code></pre></li> <li>Raises: <pre><code>Raises:\n    ValueError: Description of when and why the exception is raised.\n</code></pre></li> </ul> </li> <li> <p>In docstrings, employ <code>*</code> exclusively for any bullet points or lists (such as in descriptions or output contracts) to ensure proper line-separated display in MkDocs-generated webpages. Example:   </p><pre><code>Output Contract:\n    * Success: {\"version\": str, \"timestamp\": float}\n    * Verbose: {\"python\": str, \"platform\": str}\n    * Error: {\"error\": str, \"code\": int}\n</code></pre><p></p> </li> <li>Avoid <code>-</code> or alternative markers that could lead to rendering inconsistencies.</li> <li>Extend full Google-style docstrings to every class, function, and method, with each providing a thorough account of its functionality and integration within the file.</li> <li>Prohibit the use of <code>&lt;module&gt;</code>, <code>:param:</code>, reST directives, or any non-Google elements\u2014strict adherence to Google format is required.</li> <li>Mandate enforcement through tools like <code>pydocstyle</code> set to the \"google\" convention, embedded in CI/CD workflows to automatically block non-conforming submissions.</li> </ul>"},{"location":"ADR/0003-docstring-and-documentation-style/#repository-documentation","title":"Repository Documentation","text":"<ul> <li>Store all ADRs in <code>docs/ADR/</code> with filenames formatted as <code>XXXX-&lt;short-title&gt;.md</code>, where <code>XXXX</code> represents a zero-padded integer.</li> <li>Restrict all repository documentation (ADRs, READMEs, guides) to Markdown format only.</li> <li>Prefer <code>*</code> for Markdown bullet points. <code>-</code> is also acceptable to match GitHub/MkDocs defaults.</li> <li>Mandate inclusion of Date, Status, and Author headers in ADRs, as exemplified in this document.</li> <li>MkDocs builds from a generated source tree under <code>artifacts/docs/docs/</code> (populated via <code>make docs-prep</code> from tracked sources like <code>docs/</code>, as per ADR-0005) for automated website publication.</li> </ul>"},{"location":"ADR/0003-docstring-and-documentation-style/#consequences","title":"Consequences","text":""},{"location":"ADR/0003-docstring-and-documentation-style/#pros","title":"Pros","text":"<ul> <li>Delivers a uniformly professional codebase with reliable introspection and automated API reference generation.</li> <li>Ensures out-of-the-box compatibility with tools like MkDocs for superior documentation websites.</li> <li>Provides contributors with unambiguous, enforceable guidelines, streamlining reviews through automation and objectivity.</li> </ul>"},{"location":"ADR/0003-docstring-and-documentation-style/#cons","title":"Cons","text":"<ul> <li>Incurs upfront costs for refactoring existing non-compliant files.</li> <li>Necessitates adaptation for contributors unaccustomed to Google style or rigorous linting protocols.</li> </ul>"},{"location":"ADR/0003-docstring-and-documentation-style/#enforcement","title":"Enforcement","text":"<ul> <li>Prohibit acceptance of any code or documentation pull request that fails to comply fully with this ADR.</li> <li>Empower reviewers and CI systems to reject submissions outright for issues such as absent module-level docstrings, incomplete explanations, stylistic inconsistencies, or improper bullet formatting.</li> <li>Establish this policy as irrevocably binding, with no provisions for negotiation or exceptions.</li> </ul>"},{"location":"ADR/0004-linting-quality-security/","title":"ADR-0004: Linting, Quality, and Security Toolchain","text":""},{"location":"ADR/0004-linting-quality-security/#adr-0004-linting-quality-and-security-toolchain","title":"ADR-0004: Linting, Quality, and Security Toolchain","text":"<ul> <li>Date: 2025-08-01  </li> <li>Status: Accepted  </li> <li>Author: Bijan Mousavi  </li> </ul>"},{"location":"ADR/0004-linting-quality-security/#context","title":"Context","text":"<p>We need a single, reproducible pipeline for code style, formatting, type-safety, complexity, documentation coverage, dead code, dependency hygiene, license compliance, and security checks \u2014 identical locally and in CI. Developers should be able to run:</p> <pre><code>make lint\nmake quality\nmake security\n</code></pre> <p>and get the same results everywhere.</p> <p>We standardized on the following tools:</p> <ul> <li>Ruff for formatting, import sorting, and linting (with auto-fix where safe).</li> <li>Mypy and Pytype for static typing (Pytype runs where supported).</li> <li>Pyright for fast type checks (editor/CI parity).</li> <li>Pydocstyle (Google convention) for docstring style.</li> <li>Interrogate for documentation coverage.</li> <li>Radon for cyclomatic complexity.</li> <li>Vulture for dead code detection.</li> <li>Deptry for unused/incorrect dependencies.</li> <li>REUSE for SPDX license header compliance.</li> <li>Bandit for security static analysis.</li> <li>pip-audit for dependency vulnerability audits.</li> </ul> <p>All configuration lives under <code>config/</code> (with a few root files like <code>REUSE.toml</code>), ensuring CI/local parity.</p>"},{"location":"ADR/0004-linting-quality-security/#decision","title":"Decision","text":""},{"location":"ADR/0004-linting-quality-security/#makefile-targets","title":"Makefile Targets","text":"<p>We enforce Makefile targets to run the full toolchain consistently.</p> Lint (<code>Makefile</code>) <pre><code># Lint Configuration\n\nRUFF        := $(ACT)/ruff\nMYPY        := $(ACT)/mypy\nPYRIGHT     := $(ACT)/pyright\nPYTYPE      := $(ACT)/pytype\n\nLINT_DIRS           ?= src/bijux_rag tests\nMYPY_DIRS           ?= src/bijux_rag\nPYRIGHT_DIRS        ?= src/bijux_rag\nLINT_ARTIFACTS_DIR  ?= artifacts/lint\nRUFF_CACHE_DIR      ?= $(LINT_ARTIFACTS_DIR)/.ruff_cache\nMYPY_CACHE_DIR      ?= $(LINT_ARTIFACTS_DIR)/.mypy_cache\nPYTYPE_OUT_DIR      ?= $(LINT_ARTIFACTS_DIR)/pytype\n\n.PHONY: lint lint-artifacts lint-clean fmt type\n\nfmt: | $(VENV)\n    @mkdir -p \"$(LINT_ARTIFACTS_DIR)\" \"$(RUFF_CACHE_DIR)\"\n    @set -euo pipefail; $(RUFF) format --config config/ruff.toml --cache-dir \"$(RUFF_CACHE_DIR)\" $(LINT_DIRS)\n    @set -euo pipefail; $(RUFF) check --config config/ruff.toml --fix --cache-dir \"$(RUFF_CACHE_DIR)\" $(LINT_DIRS)\n    @printf \"OK\\n\" &gt; \"$(LINT_ARTIFACTS_DIR)/_fmt\"\n\nlint: lint-artifacts type\n    @echo \"\u2714 Linting completed (artifacts in '$(LINT_ARTIFACTS_DIR)')\"\n\nlint-artifacts: | $(VENV)\n    @mkdir -p \"$(LINT_ARTIFACTS_DIR)\" \"$(RUFF_CACHE_DIR)\" \"$(MYPY_CACHE_DIR)\"\n    @set -euo pipefail; $(RUFF) format --config config/ruff.toml --check --cache-dir \"$(RUFF_CACHE_DIR)\" $(LINT_DIRS) 2&gt;&amp;1 | tee \"$(LINT_ARTIFACTS_DIR)/ruff-format.log\"\n    @set -euo pipefail; $(RUFF) check --config config/ruff.toml --cache-dir \"$(RUFF_CACHE_DIR)\" $(LINT_DIRS) 2&gt;&amp;1 | tee \"$(LINT_ARTIFACTS_DIR)/ruff.log\"\n    @set -euo pipefail; $(MYPY) --config-file config/mypy.ini --cache-dir \"$(MYPY_CACHE_DIR)\" $(MYPY_DIRS) 2&gt;&amp;1 | tee \"$(LINT_ARTIFACTS_DIR)/mypy.log\"\n    @set -euo pipefail; $(PYRIGHT) --project config/pyrightconfig.json --pythonpath src $(PYRIGHT_DIRS) 2&gt;&amp;1 | tee \"$(LINT_ARTIFACTS_DIR)/pyright.log\"\n    @mkdir -p \"$(PYTYPE_OUT_DIR)\"\n    @set -euo pipefail; $(PYTYPE) --config=config/pytype.cfg --output=\"$(PYTYPE_OUT_DIR)\" src/bijux_rag/boundaries 2&gt;&amp;1 | tee \"$(LINT_ARTIFACTS_DIR)/pytype.log\"\n    @[ -d .ruff_cache ] &amp;&amp; rm -rf .ruff_cache || true\n    @[ -d .mypy_cache ] &amp;&amp; rm -rf .mypy_cache || true\n    @printf \"OK\\n\" &gt; \"$(LINT_ARTIFACTS_DIR)/_passed\"\n\ntype: | $(VENV)\n    @mkdir -p \"$(LINT_ARTIFACTS_DIR)\" \"$(MYPY_CACHE_DIR)\"\n    @set -euo pipefail; $(PYRIGHT) --project config/pyrightconfig.json --pythonpath src $(PYRIGHT_DIRS) 2&gt;&amp;1 | tee \"$(LINT_ARTIFACTS_DIR)/pyright.log\"\n\nlint-clean:\n    @echo \"\u2192 Cleaning lint artifacts\"\n    @rm -rf \"$(LINT_ARTIFACTS_DIR)\" .ruff_cache .mypy_cache || true\n    @echo \"\u2714 done\"\n\n##@ Lint\nfmt: ## Auto-format with ruff (format + autofix)\nlint: ## Run ruff + mypy + pyright (check-only, caches under artifacts/lint)\nlint-clean: ## Remove lint artifacts\n</code></pre> Quality (<code>Makefile</code>) <pre><code># Quality checks (dead code, deps, REUSE, doc coverage)\n\nQUALITY_PATHS       ?= src/bijux_rag\nINTERROGATE_PATHS   ?= src/bijux_rag\nQUALITY_ARTIFACTS_DIR ?= artifacts/quality\nQUALITY_OK_MARKER     := $(QUALITY_ARTIFACTS_DIR)/_passed\n\nVULTURE     := $(ACT)/vulture\nDEPTRY      := $(ACT)/deptry\nREUSE       := $(ACT)/reuse\nINTERROGATE := $(ACT)/interrogate\n\n.PHONY: quality quality-clean interrogate-report\n\nquality:\n    @echo \"\u2192 Quality checks\"\n    @mkdir -p \"$(QUALITY_ARTIFACTS_DIR)\"\n    @echo \"   - Dead code (vulture)\"\n    @$(VULTURE) $(QUALITY_PATHS) --min-confidence 80 2&gt;&amp;1 | tee \"$(QUALITY_ARTIFACTS_DIR)/vulture.log\"\n    @echo \"   - Dependency hygiene (deptry)\"\n    @$(DEPTRY) $(QUALITY_PATHS) 2&gt;&amp;1 | tee \"$(QUALITY_ARTIFACTS_DIR)/deptry.log\"\n    @echo \"   - REUSE compliance\"\n    @$(REUSE) lint 2&gt;&amp;1 | tee \"$(QUALITY_ARTIFACTS_DIR)/reuse.log\"\n    @$(MAKE) interrogate-report\n    @printf \"OK\\n\" &gt;\"$(QUALITY_OK_MARKER)\"\n    @echo \"\u2714 Quality complete\"\n\ninterrogate-report:\n    @mkdir -p \"$(QUALITY_ARTIFACTS_DIR)\"\n    @set +e; OUT=\"$$( $(INTERROGATE) --verbose $(INTERROGATE_PATHS) )\"; rc=$$?; \\\n    printf '%s\\n' \"$$OUT\" &gt;\"$(QUALITY_ARTIFACTS_DIR)/interrogate.full.txt\"; \\\n    printf '%s\\n' \"$$OUT\" | awk -F'|' 'NR&gt;3 &amp;&amp; $$0 ~ /^\\|/ {name=$$2; cov=$$6; gsub(/^[ \\t]+|[ \\t]+$$/,\"\",name); gsub(/^[ \\t]+|[ \\t]+$$/,\"\",cov); if (name !~ /^-+$$/ &amp;&amp; cov != \"100%\") printf(\"  - %s (%s)\\n\", name, cov);}' \\\n      &gt;\"$(QUALITY_ARTIFACTS_DIR)/interrogate.offenders.txt\"; \\\n    exit $$rc\n\nquality-clean:\n    @echo \"\u2192 Cleaning quality artifacts\"\n    @rm -rf \"$(QUALITY_ARTIFACTS_DIR)\"\n\n##@ Quality\nquality: ## Run vulture, deptry, reuse, interrogate (artifacts under artifacts/quality)\nquality-clean: ## Remove quality artifacts\n</code></pre> Security (<code>Makefile</code>) <pre><code># Security checks (Bandit + pip-audit)\n\nSECURITY_PATHS       ?= src/bijux_rag\nSECURITY_REPORT_DIR  ?= artifacts/security\nBANDIT               := $(ACT)/bandit\nPIP_AUDIT            := $(ACT)/pip-audit\nSECURITY_IGNORE_IDS  ?= PYSEC-2022-42969\nSECURITY_IGNORE_FLAGS = $(foreach V,$(SECURITY_IGNORE_IDS),--ignore-vuln $(V))\nBANDIT_OPTS          ?= --severity-level high --confidence-level high -s B101,B311\n\n.PHONY: security security-bandit security-audit security-clean\n\nsecurity: security-bandit security-audit\n\nsecurity-bandit:\n    @mkdir -p \"$(SECURITY_REPORT_DIR)\"\n    @echo \"\u2192 Bandit\"\n    @$(BANDIT) $(BANDIT_OPTS) -r \"$(SECURITY_PATHS)\" -x \".venv,.tox,build,dist,tests\" -f json -o \"$(SECURITY_REPORT_DIR)/bandit.json\"\n    @$(BANDIT) $(BANDIT_OPTS) -r \"$(SECURITY_PATHS)\" -x \".venv,.tox,build,dist,tests\" 2&gt;&amp;1 | tee \"$(SECURITY_REPORT_DIR)/bandit.txt\"\n\nsecurity-audit:\n    @mkdir -p \"$(SECURITY_REPORT_DIR)\"\n    @echo \"\u2192 pip-audit\"\n    @$(PIP_AUDIT) $(SECURITY_IGNORE_FLAGS) --progress-spinner off --format json -o \"$(SECURITY_REPORT_DIR)/pip-audit.json\"\n    @$(PIP_AUDIT) $(SECURITY_IGNORE_FLAGS) --progress-spinner off 2&gt;&amp;1 | tee \"$(SECURITY_REPORT_DIR)/pip-audit.txt\"\n\nsecurity-clean:\n    @rm -rf \"$(SECURITY_REPORT_DIR)\"\n\n##@ Security\nsecurity: ## Run Bandit + pip-audit (artifacts under artifacts/security)\nsecurity-clean: ## Remove security artifacts\n</code></pre> <p>This setup supports whole-project runs as well as per-directory/per-file runs, with reasonable exclusions for generated or template content.</p>"},{"location":"ADR/0004-linting-quality-security/#tool-configurations","title":"Tool Configurations","text":"<p>The toolchain is driven by unified configs:</p> Ruff (<code>config/ruff.toml</code>) <pre><code>line-length = 100\ntarget-version = \"py311\"\nextend-exclude = [\"build\", \"dist\", \".venv\", \"node_modules\", \"artifacts\", \"src/bijux_rag/_version.py\"]\n\n[lint]\nselect = [\"E\", \"F\", \"I\", \"B\"]\nignore = [\"E501\", \"B905\"]\n\n[format]\nquote-style = \"double\"\nindent-style = \"space\"\n</code></pre> Mypy (<code>config/mypy.ini</code>) <pre><code>[mypy]\npython_version = 3.11\nmypy_path = src\nignore_missing_imports = True\nfollow_imports = normal\nwarn_unused_ignores = True\nwarn_redundant_casts = True\nwarn_unreachable = True\nstrict_optional = True\nnamespace_packages = True\npretty = True\nshow_error_codes = True\ncheck_untyped_defs = True\ndisallow_incomplete_defs = True\ndisallow_untyped_defs = True\nno_implicit_optional = True\nwarn_return_any = True\n\n[pydantic-mypy]\ninit_forbid_extra = True\ninit_typed = True\nwarn_required_dynamic_aliases = True\nwarn_untyped_fields = True\n</code></pre> Pyright (<code>config/pyrightconfig.json</code>) <pre><code>{\n  \"venvPath\": \"..\",\n  \"venv\": \".venv\",\n  \"include\": [\n    \"../src/bijux_rag/boundaries\"\n  ],\n  \"stubPath\": \"../typings\",\n  \"ignore\": [\n    \"../src/bijux_rag/rag\",\n    \"../src/bijux_rag/core\",\n    \"../src/bijux_rag/fp\",\n    \"../src/bijux_rag/result\",\n    \"../src/bijux_rag/domain\",\n    \"../src/bijux_rag/interop\",\n    \"../src/bijux_rag/pipelines\",\n    \"../src/bijux_rag/policies\",\n    \"../src/bijux_rag/streaming\",\n    \"../tests\"\n  ],\n  \"exclude\": [\n    \"../tests\",\n    \"../build\",\n    \"../dist\",\n    \"../artifacts\",\n    \"../node_modules\",\n    \"../.venv\",\n    \"../.git\",\n    \"../src/bijux_rag/__init__.py\",\n    \"../src/bijux_rag/tree\"\n  ],\n  \"typeCheckingMode\": \"basic\",\n  \"pythonVersion\": \"3.11\",\n  \"reportMissingTypeStubs\": \"warning\",\n  \"reportMissingImports\": \"warning\",\n  \"reportUnknownVariableType\": \"none\",\n  \"reportUnknownParameterType\": \"none\",\n  \"reportUnknownMemberType\": \"none\",\n  \"reportUnknownArgumentType\": \"none\",\n  \"reportUnusedFunction\": \"none\",\n  \"reportPrivateUsage\": \"none\",\n  \"reportUnnecessaryIsInstance\": \"none\",\n  \"useLibraryCodeForTypes\": true\n}\n</code></pre> Deptry (<code>pyproject.toml</code>) <pre><code>\n</code></pre> Interrogate (<code>pyproject.toml</code>) <pre><code>\n</code></pre> REUSE (<code>REUSE.toml</code>) <pre><code>version = 1\n\n[[annotations]]\npath = [\n  \"**/*.png\", \"**/*.svg\", \"**/*.ico\", \"**/*.gif\", \"**/*.jpg\", \"**/*.jpeg\",\n  \"**/*.html\", \"**/*.toml\", \"**/*.ini\", \"**/*.cfg\", \"**/*.conf\", \"**/*.css\",\n  \"**/*.env\", \"**/*.env.*\", \"**/*.yaml\", \"**/*.yml\", \"**/*.json\",\n  \"**/*.cff\", \"**/.editorconfig\", \".gitattributes\", \".gitignore\",\n  \"artifacts/**\"\n]\nprecedence = \"override\"\nSPDX-License-Identifier = \"CC0-1.0\"\nSPDX-FileCopyrightText = \"\u00a9 2025 Bijan Mousavi\"\n\n[[annotations]]\npath = [\"**/*.md\"]\nprecedence = \"closest\"\nSPDX-License-Identifier = \"MIT\"\nSPDX-FileCopyrightText = \"\u00a9 2025 Bijan Mousavi\"\n\n[[annotations]]\npath = [\"**/*.py\", \"**/*.pyi\", \"**/*.sh\", \"**/*.mk\", \"Makefile\", \"Dockerfile\", \"Dockerfile.*\"]\nprecedence = \"closest\"\nSPDX-License-Identifier = \"MIT\"\nSPDX-FileCopyrightText = \"\u00a9 2025 Bijan Mousavi\"\n</code></pre> <p>Docstring Style Enforcement</p> <p>We mandate Google-style docstrings via Pydocstyle (enforced in Makefile):</p> <pre><code>pydocstyle --convention=google path/to/file.py\n</code></pre> <p>Interrogate enforces documentation coverage thresholds as configured.</p>"},{"location":"ADR/0004-linting-quality-security/#ci-integration","title":"CI Integration","text":"<ul> <li><code>make lint</code> runs over <code>src/</code> and <code>tests/</code>.</li> <li><code>make quality</code> and <code>make security</code> run project-wide.</li> <li>All Makefile targets are configured to write their reports and logs to the canonical locations defined in ADR-0005.</li> <li>Any failure blocks the build; no overrides.</li> </ul>"},{"location":"ADR/0004-linting-quality-security/#consequences","title":"Consequences","text":""},{"location":"ADR/0004-linting-quality-security/#pros","title":"Pros","text":"<ul> <li>Uniform enforcement across the repo; no drift.</li> <li>One tool (Ruff) handles formatting, import sorting, and linting with fast auto-fixes.</li> <li>Strong typing via Mypy, Pytype (where supported), and Pyright.</li> <li>Doc style &amp; coverage enforced via Pydocstyle + Interrogate.</li> <li>Maintainability boosted by Vulture (dead code), Deptry (deps), Radon (complexity).</li> <li>SPDX compliance via REUSE.</li> <li>Security posture improved through Bandit + pip-audit.</li> <li>All configs centralized under <code>config/</code>, ensuring local/CI parity.</li> </ul>"},{"location":"ADR/0004-linting-quality-security/#cons","title":"Cons","text":"<ul> <li>Initial setup and periodic rule maintenance.</li> <li>Contributors must align with strict rules and workflow.</li> </ul>"},{"location":"ADR/0004-linting-quality-security/#enforcement","title":"Enforcement","text":"<ul> <li>Code is accepted only if it passes all configured targets and checks in this ADR.</li> <li>Reviewers &amp; CI must reject non-compliant changes (lint, quality, security, or config deviations).</li> <li>This policy is binding to preserve the integrity of the toolchain.</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/","title":"ADR-0005: Enforcing Zero-Root-Pollution via Makefile-Orchestrated Artifact Containment","text":""},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#adr-0005-enforcing-zero-root-pollution-via-makefile-orchestrated-artifact-containment","title":"ADR-0005: Enforcing Zero-Root-Pollution via Makefile-Orchestrated Artifact Containment","text":"<ul> <li>Date: 2025-08-20</li> <li>Status: Accepted</li> <li>Author: Bijan Mousavi</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#context","title":"Context","text":"<p>Build, test, docs, and release steps produce transient outputs (wheels/sdists, coverage reports, HTML sites, schemas). When these spill into the repo root or source trees, they clutter the working copy, risk accidental commits, and make CI/release packaging brittle.</p>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#decision","title":"Decision","text":"<p>All generated outputs must be written beneath a single top-level directory: <code>artifacts/</code>. No Make/Tox/CI task may write transient files to the repo root or source trees. Standard caches (e.g., <code>.venv/</code>, <code>.tox/</code>, <code>.pytest_cache/</code>) are permitted and ignored via <code>.gitignore</code>.</p> <p>This policy is enforced centrally by the Makefile system. The root <code>Makefile</code> and <code>makefiles/*</code> define orchestration and output paths (<code>ARTIFACTS ?= artifacts</code>). Tox and GitHub Actions call Make targets; they do not choose paths.</p>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#canonical-layout-generated-only","title":"Canonical Layout (Generated Only)","text":"<pre><code>artifacts/\n  build/            # wheels/sdists built locally\n  docs/\n    docs/           # generated MkDocs inputs\n    site/           # MkDocs output\n  test/\n    htmlcov/        # coverage HTML\n    coverage.xml    # coverage XML\n    junit*.xml      # test reports\n    hypothesis/     # Hypothesis DB\n    benchmarks/     # benchmark results\n    tmp/            # temp test files\n  api/              # schemas, API logs/reports\n  sbom/             # SBOM outputs\n  citation/         # citation exports\n  quality/          # interrogate, vulture, deptry, reuse, etc.\n  security/         # bandit, pip-audit, etc.\n  lint/             # linter/type checker reports\n</code></pre> <p>Note: Locally we emit to <code>artifacts/build/</code>. In CI, the uploaded artifact named <code>dist</code> extracts as <code>artifacts/dist/</code> when downloaded\u2014both represent the same build bundle at different stages.</p> <p>Tracked sources (e.g., <code>pyproject.toml</code>, <code>README.md</code>, <code>LICENSE</code>, <code>CITATION.cff</code>) remain in place and are not artifacts.</p>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#rationale","title":"Rationale","text":"<ul> <li>Clean Working Tree: Routine tasks don\u2019t dirty the repo; <code>git status</code> stays meaningful.</li> <li>Deterministic Pipelines: CI and docs deploy hydrate exclusively from <code>artifacts/**</code>.</li> <li>Curated Releases: GitHub Releases contain concise, named bundles (ZIP/tar.gz per subtree), not thousands of loose files.</li> <li>Safe Docs Builds: MkDocs reads <code>artifacts/docs/docs</code> \u2192 writes <code>artifacts/docs/site</code>; required pages are asserted.</li> <li>Reproducibility: Uniform paths across local and CI; caches remain standard and ignored.</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#enforcement","title":"Enforcement","text":""},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#local-make-tox","title":"Local (Make + Tox)","text":"<ul> <li><code>ARTIFACTS ?= artifacts</code> in the root <code>Makefile</code>; sub-recipes in <code>makefiles/*</code> route outputs under that root (e.g., <code>makefiles/test.mk</code> \u2192 <code>artifacts/test/</code>; integrates with ADR-0004 toolchain targets like <code>make lint</code> for logs/caches under <code>artifacts/lint/</code>).</li> <li>Tox environments call Make targets; they do not set output paths directly.</li> <li>For docs, <code>make docs-prep</code> copies tracked sources (e.g., <code>docs/ADR/</code>) into <code>artifacts/docs/docs/</code> before build (aligning with ADR-0003's storage rules).</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#ci-github-actions","title":"CI (GitHub Actions)","text":"<ul> <li><code>ci.yml</code> (CI workflow) uploads only from <code>artifacts/**</code>.</li> <li><code>deploy-docs.yml</code> (Deploy Docs workflow) hydrates into <code>./artifacts/**</code>, builds from <code>artifacts/docs/docs</code> to <code>artifacts/docs/site</code>, and checks required pages.</li> <li><code>publish.yml</code> (Publish to PyPI workflow) assembles release bundles from <code>artifacts/**</code>, computes checksums for the build bundle, and attaches curated ZIPs (tests per-py, lint, quality, security, api, docs, sbom, citation, build).</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#consequences","title":"Consequences","text":""},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#positive","title":"Positive","text":"<ul> <li>Consistent paths locally and in CI.</li> <li>Simpler evidence collection and release packaging.</li> <li>Lower risk of committing transients.</li> <li>Docs completeness enforced before deploy.</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#trade-offs","title":"Trade-offs","text":"<ul> <li>Some tools require output redirection or a post-step move (handled in Make).</li> <li>Initial refactors to Make/Tox; validated by CI.</li> <li>PRs introducing new tools must adhere to the layout (review + CI enforce it).</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#invariants","title":"Invariants","text":"<ul> <li>Make targets do not write outside <code>$(ARTIFACTS)</code> (except standard caches). </li> <li>CI uploads/downloads only <code>artifacts/**</code>. </li> <li>Docs build from <code>artifacts/docs/docs</code> \u2192 <code>artifacts/docs/site</code>. </li> <li>Releases assemble from <code>artifacts/**</code> (build bundle appears as <code>artifacts/build/</code> locally and <code>artifacts/dist/</code> when retrieved from CI).</li> </ul>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#compliance-examples","title":"Compliance Examples","text":"<ul> <li>Build Wheels/SDist</li> </ul> <pre><code>python -m build --outdir artifacts/build\n</code></pre> <ul> <li>Tests + Coverage + JUnit</li> </ul> <pre><code>pytest --cov \\\n       --cov-report=xml:artifacts/test/coverage.xml \\\n       --cov-report=html:artifacts/test/htmlcov \\\n       --junitxml=artifacts/test/junit.xml\n</code></pre> <ul> <li>MkDocs</li> </ul> <pre><code>docs_dir: artifacts/docs/docs\nsite_dir: artifacts/docs/site\n</code></pre>"},{"location":"ADR/0005-zero-root-pollution-artifacts-only/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Tool defaults scattered across the repo \u2014 rejected (clutter, fragility). </li> <li>Per-tool output roots \u2014 rejected (fragmentation). </li> <li>CI-only containment \u2014 rejected (misses local benefits).</li> </ul>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":"<p>This project follows a functional core / explicit-IO boundaries layout:</p> <ul> <li><code>src/bijux_rag/rag</code>: domain logic (indexes, embedders, generators, rerankers, app orchestration).</li> <li><code>src/bijux_rag/boundaries</code>: adapters (FastAPI, CLI, file shims).</li> <li><code>tests/</code>: unit + e2e + eval suite gates.</li> <li><code>docs/ADR</code>: design decisions mirrored from bijux-cli standards (zero-root-pollution, lint/quality/security posture, docstring style).</li> </ul> <p>See ADRs for rationale and trade-offs.</p>"},{"location":"architecture/#top","title":"Architecture Decision Records","text":"<ul> <li>ADR 0003: Docstring And Documentation Style</li> <li>ADR 0004: Linting Quality Security</li> <li>ADR 0005: Zero-Root-Pollution \u2014 Artifacts Only</li> </ul>"},{"location":"architecture/adr/","title":"Adr","text":""},{"location":"architecture/adr/#adrs","title":"ADRs","text":""},{"location":"architecture/adr/#top","title":"Architecture Decision Records","text":"<ul> <li>ADR 0003: Docstring And Documentation Style</li> <li>ADR 0004: Linting Quality Security</li> <li>ADR 0005: Zero-Root-Pollution \u2014 Artifacts Only</li> </ul>"},{"location":"reference/cli/","title":"Reference","text":""},{"location":"reference/cli/#cli-reference","title":"CLI Reference","text":"<p>The <code>bijux-rag</code> CLI is built with Typer. Common commands:</p> <ul> <li><code>bijux-rag chunks --input docs.csv --output chunks.jsonl</code></li> <li><code>bijux-rag index-build --input corpus.csv --out index.msgpack --backend bm25</code></li> <li><code>bijux-rag retrieve --index index.msgpack --query \"what is bm25?\"</code></li> <li><code>bijux-rag ask --index index.msgpack --query \"...\" --top-k 5</code></li> <li><code>bijux-rag eval --suite tests/eval --index index.msgpack --baseline tests/eval/baselines/bm25/default/metrics.json</code></li> </ul> <p>Typer auto-generates <code>--help</code>; run <code>bijux-rag --help</code> or subcommand <code>--help</code> for parameter details.</p>"},{"location":"reference/http_api/","title":"HTTP API (FastAPI)","text":""},{"location":"reference/http_api/#http-api-fastapi","title":"HTTP API (FastAPI)","text":"<p>FastAPI app lives in <code>bijux_rag.boundaries.web.fastapi_app</code>. The published OpenAPI schema is versioned at <code>api/v1/schema.yaml</code>.</p> <ul> <li><code>POST /v1/index/build</code> \u2014 build an index from documents (bm25 or numpy-cosine).</li> <li><code>POST /v1/retrieve</code> \u2014 retrieve top-k candidates from a saved index.</li> <li><code>POST /v1/ask</code> \u2014 generate an answer with citations grounded in retrieved chunks.</li> <li><code>POST /v1/chunks</code> \u2014 legacy chunk/embed endpoint.</li> <li><code>GET /v1/healthz</code> \u2014 health check.</li> </ul> <p>To view the full OpenAPI spec in docs, mkdocs renders <code>api/v1/schema.yaml</code>. Clients can be generated directly from that file.</p>"},{"location":"reference/python/","title":"Python API Reference","text":""},{"location":"reference/python/#python-api-reference","title":"Python API Reference","text":"<p>The core entry points are documented via <code>mkdocstrings</code>. Key modules:</p>"},{"location":"reference/python/#bijux_rag.rag.app","title":"bijux_rag.rag.app","text":"<p>Application services for the 'real RAG' path.</p> This module wires <p>clean -&gt; chunk -&gt; index -&gt; retrieve -&gt; (optional rerank) -&gt; generate.</p> <p>Both CLI and FastAPI boundary call into this layer to avoid drift.</p>"},{"location":"reference/python/#bijux_rag.rag.app.RagApp","title":"RagApp  <code>dataclass</code>","text":"<pre><code>RagApp(\n    generator=ExtractiveGenerator(),\n    reranker=LexicalOverlapReranker(),\n    profile=\"default\",\n)\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.app.RagBuildConfig","title":"RagBuildConfig  <code>dataclass</code>","text":"<pre><code>RagBuildConfig(\n    chunk_env,\n    backend=\"bm25\",\n    embedder=\"hash16\",\n    sbert_model=\"all-MiniLM-L6-v2\",\n    bm25_buckets=2048,\n)\n</code></pre> <p>RAG build configuration.</p>"},{"location":"reference/python/#bijux_rag.rag.app.RagIndex","title":"RagIndex  <code>dataclass</code>","text":"<pre><code>RagIndex(backend, index, fingerprint, schema_version=1)\n</code></pre> <p>In-memory index wrapper for deterministic CI profile.</p>"},{"location":"reference/python/#bijux_rag.rag.app.ask","title":"ask","text":"<pre><code>ask(\n    *,\n    index_path,\n    query,\n    top_k=5,\n    filters=None,\n    embedder=None,\n    rerank=True,\n)\n</code></pre> <p>Retrieve and answer with citations.</p> Source code in <code>src/bijux_rag/rag/app.py</code> <pre><code>def ask(\n    *,\n    index_path: Path,\n    query: str,\n    top_k: int = 5,\n    filters: Mapping[str, str] | None = None,\n    embedder: Embedder | None = None,\n    rerank: bool = True,\n) -&gt; Answer:\n    \"\"\"Retrieve and answer with citations.\"\"\"\n\n    cands = retrieve(\n        index_path=index_path,\n        query=query,\n        top_k=max(20, int(top_k)),\n        filters=filters,\n        embedder=embedder,\n    )\n    if rerank:\n        cands = LexicalOverlapReranker().rerank(query=query, candidates=cands, top_k=int(top_k))\n    else:\n        cands = cands[: int(top_k)]\n    return ExtractiveGenerator().generate(query=query, candidates=cands)\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.app.build_index_from_csv","title":"build_index_from_csv","text":"<pre><code>build_index_from_csv(*, csv_path, out_path, cfg)\n</code></pre> <p>Build and persist an index.</p> <p>Returns:</p> Type Description <code>str</code> <p>The index fingerprint.</p> Source code in <code>src/bijux_rag/rag/app.py</code> <pre><code>def build_index_from_csv(*, csv_path: Path, out_path: Path, cfg: RagBuildConfig) -&gt; str:\n    \"\"\"Build and persist an index.\n\n    Returns:\n        The index fingerprint.\n    \"\"\"\n\n    chunks = ingest_csv_to_chunks(csv_path=csv_path, env=cfg.chunk_env)\n    if cfg.backend == \"bm25\":\n        idx = build_bm25_index(chunks=chunks, buckets=cfg.bm25_buckets)\n        idx.save(str(out_path))\n        return idx.fingerprint\n\n    if cfg.backend == \"numpy-cosine\":\n        emb = _make_embedder(cfg)\n        idx = build_numpy_cosine_index(chunks=chunks, embedder=emb)\n        idx.save(str(out_path))\n        return idx.fingerprint\n\n    raise ValueError(f\"unknown index backend: {cfg.backend}\")\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.app.ingest_csv_to_chunks","title":"ingest_csv_to_chunks","text":"<pre><code>ingest_csv_to_chunks(*, csv_path, env)\n</code></pre> <p>Ingest a CSV and return chunks.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>Path</code> <p>CSV path with columns: doc_id,title,abstract,categories.</p> required <code>env</code> <code>RagEnv</code> <p>Chunking configuration.</p> required <p>Returns:</p> Type Description <code>list[Chunk]</code> <p>A list of chunks (without embeddings for lexical backends).</p> Source code in <code>src/bijux_rag/rag/app.py</code> <pre><code>def ingest_csv_to_chunks(*, csv_path: Path, env: RagEnv) -&gt; list[Chunk]:\n    \"\"\"Ingest a CSV and return chunks.\n\n    Args:\n        csv_path: CSV path with columns: doc_id,title,abstract,categories.\n        env: Chunking configuration.\n\n    Returns:\n        A list of chunks (without embeddings for lexical backends).\n    \"\"\"\n\n    storage = FileStorage()\n    docs: list[RawDoc] = []\n    errors: list[str] = []\n    for res in storage.read_docs(str(csv_path)):\n        if is_ok(res):\n            docs.append(res.value)\n        elif is_err(res):\n            errors.append(f\"{res.error.code}: {res.error.msg}\")\n        else:  # pragma: no cover\n            errors.append(\"unknown error\")\n\n    if errors:\n        # Fail fast: ingestion is a boundary operation.\n        raise ValueError(\"CSV parse failures: \" + \"; \".join(errors[:3]))\n\n    cleaned = list(_iter_clean_docs(docs))\n    raw_chunks = list(_iter_chunks(cleaned, env))\n    return [\n        Chunk(\n            doc_id=c.doc_id,\n            text=c.text,\n            start=c.start,\n            end=c.end,\n            metadata=c.metadata,\n            embedding=(),\n        )\n        for c in raw_chunks\n    ]\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.app.ingest_docs_to_chunks","title":"ingest_docs_to_chunks","text":"<pre><code>ingest_docs_to_chunks(*, docs, env)\n</code></pre> <p>Ingest in-memory docs and return chunks.</p> Source code in <code>src/bijux_rag/rag/app.py</code> <pre><code>def ingest_docs_to_chunks(*, docs: Iterable[RawDoc], env: RagEnv) -&gt; list[Chunk]:\n    \"\"\"Ingest in-memory docs and return chunks.\"\"\"\n\n    cleaned = list(_iter_clean_docs(docs))\n    raw_chunks = list(_iter_chunks(cleaned, env))\n    return [\n        Chunk(\n            doc_id=c.doc_id,\n            text=c.text,\n            start=c.start,\n            end=c.end,\n            metadata=c.metadata,\n            embedding=(),\n        )\n        for c in raw_chunks\n    ]\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.app.parse_filters","title":"parse_filters","text":"<pre><code>parse_filters(filters)\n</code></pre> <p>Parse CLI/API filters.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>list[str] | None</code> <p>list like [\"category=cs.AI\", \"doc_id=foo\"].</p> required Source code in <code>src/bijux_rag/rag/app.py</code> <pre><code>def parse_filters(filters: list[str] | None) -&gt; dict[str, str]:\n    \"\"\"Parse CLI/API filters.\n\n    Args:\n        filters: list like [\"category=cs.AI\", \"doc_id=foo\"].\n    \"\"\"\n\n    out: dict[str, str] = {}\n    for f in filters or []:\n        if \"=\" not in f:\n            raise ValueError(f\"invalid filter: {f}\")\n        k, v = f.split(\"=\", 1)\n        k = k.strip()\n        v = v.strip()\n        if not k or not v:\n            raise ValueError(f\"invalid filter: {f}\")\n        out[k] = v\n    return out\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.app.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    *,\n    index_path,\n    query,\n    top_k=5,\n    filters=None,\n    embedder=None,\n)\n</code></pre> <p>Retrieve candidates from a persisted index.</p> Source code in <code>src/bijux_rag/rag/app.py</code> <pre><code>def retrieve(\n    *,\n    index_path: Path,\n    query: str,\n    top_k: int = 5,\n    filters: Mapping[str, str] | None = None,\n    embedder: Embedder | None = None,\n) -&gt; list[Candidate]:\n    \"\"\"Retrieve candidates from a persisted index.\"\"\"\n\n    idx = load_index(str(index_path))\n\n    if isinstance(idx, NumpyCosineIndex) and embedder is None:\n        # Default embedder based on index spec.\n        if idx.spec.model.startswith(\"sbert:\"):\n            embedder = SentenceTransformersEmbedder(model_name=idx.spec.model.split(\":\", 1)[1])\n        else:\n            embedder = HashEmbedder()\n\n    return idx.retrieve(query=query, top_k=int(top_k), filters=filters, embedder=embedder)\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.indexes","title":"bijux_rag.rag.indexes","text":"<p>Reference indexes.</p> <p>Two backends are provided out of the box: * NumpyCosineIndex: small/medium corpora, deterministic, dependency-free. * BM25Index: CI-friendly lexical retrieval without model downloads.</p> <p>Persistence format: msgpack (schema_versioned).</p>"},{"location":"reference/python/#bijux_rag.rag.indexes.BM25Index","title":"BM25Index  <code>dataclass</code>","text":"<pre><code>BM25Index(\n    chunks,\n    buckets,\n    df,\n    tfs,\n    doc_len,\n    avg_dl,\n    k1=1.2,\n    b=0.75,\n)\n</code></pre> <p>Hashed-token BM25 index.</p> <p>This is a practical, CI-friendly retrieval baseline: - deterministic - no large model downloads - supports metadata filters</p>"},{"location":"reference/python/#bijux_rag.rag.indexes.NumpyCosineIndex","title":"NumpyCosineIndex  <code>dataclass</code>","text":"<pre><code>NumpyCosineIndex(chunks, vectors, spec)\n</code></pre> <p>Dense vector index using cosine similarity.</p>"},{"location":"reference/python/#bijux_rag.rag.indexes.build_bm25_index","title":"build_bm25_index","text":"<pre><code>build_bm25_index(*, chunks, buckets=2048, k1=1.2, b=0.75)\n</code></pre> <p>Build a hashed-token BM25 index.</p> Source code in <code>src/bijux_rag/rag/indexes.py</code> <pre><code>def build_bm25_index(\n    *, chunks: Sequence[Chunk], buckets: int = 2048, k1: float = 1.2, b: float = 0.75\n) -&gt; BM25Index:\n    \"\"\"Build a hashed-token BM25 index.\"\"\"\n\n    if not chunks:\n        raise ValueError(\"cannot build index from empty chunk list\")\n    n = len(chunks)\n    df = np.zeros((buckets,), dtype=np.int32)\n    tfs: list[tuple[tuple[int, int], ...]] = []\n    doc_len = np.zeros((n,), dtype=np.int32)\n\n    ordered_chunks = sorted(chunks, key=lambda c: c.chunk_id)\n\n    # Compute per-chunk term counts and bucket doc-frequencies.\n    for i, c in enumerate(ordered_chunks):\n        toks = _tokenize(c.text)\n        doc_len[i] = np.int32(len(toks))\n        counts: dict[int, int] = {}\n        seen: set[int] = set()\n        for t in toks:\n            bucket = _stable_token_bucket(t, buckets=buckets)\n            counts[bucket] = counts.get(bucket, 0) + 1\n            seen.add(bucket)\n        for bkt in seen:\n            df[bkt] += 1\n        tfs.append(tuple(sorted(counts.items())))\n\n    avg_dl = float(doc_len.mean()) if n else 0.0\n    return BM25Index(\n        chunks=tuple(ordered_chunks),\n        buckets=buckets,\n        df=df,\n        tfs=tuple(tfs),\n        doc_len=doc_len,\n        avg_dl=avg_dl,\n        k1=float(k1),\n        b=float(b),\n    )\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.indexes.build_numpy_cosine_index","title":"build_numpy_cosine_index","text":"<pre><code>build_numpy_cosine_index(*, chunks, embedder)\n</code></pre> <p>Build a dense index from chunk texts.</p> Source code in <code>src/bijux_rag/rag/indexes.py</code> <pre><code>def build_numpy_cosine_index(*, chunks: Sequence[Chunk], embedder: Embedder) -&gt; NumpyCosineIndex:\n    \"\"\"Build a dense index from chunk texts.\"\"\"\n\n    if not chunks:\n        raise ValueError(\"cannot build index from empty chunk list\")\n    ordered_chunks = sorted(chunks, key=lambda c: c.chunk_id)\n    spec = embedder.spec\n    texts = [c.text for c in ordered_chunks]\n    vecs = embedder.embed_texts(texts)\n    if vecs.ndim != 2:\n        raise ValueError(\"embedder must return a 2D array\")\n    if vecs.shape[0] != len(ordered_chunks):\n        raise ValueError(\"embedder output size mismatch\")\n    # Spec dim is enforced at the boundary (this is the point of EmbeddingSpec).\n    if vecs.shape[1] != spec.dim:\n        # Allow embedders to report placeholder dims; in that case, take the real dim.\n        spec = EmbeddingSpec(\n            model=spec.model, dim=int(vecs.shape[1]), metric=spec.metric, normalized=spec.normalized\n        )\n    arr = np.asarray(vecs, dtype=np.float32)\n    if spec.normalized:\n        arr = _l2_normalize(arr)\n    out_chunks = tuple(\n        Chunk(\n            doc_id=c.doc_id,\n            text=c.text,\n            start=c.start,\n            end=c.end,\n            metadata=c.metadata,\n            embedding=tuple(float(x) for x in arr[i].tolist()),\n            embedding_spec=spec,\n        )\n        for i, c in enumerate(ordered_chunks)\n    )\n    return NumpyCosineIndex(chunks=out_chunks, vectors=arr, spec=spec)\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.indexes.load_index","title":"load_index","text":"<pre><code>load_index(path)\n</code></pre> <p>Load an index from disk.</p> Source code in <code>src/bijux_rag/rag/indexes.py</code> <pre><code>def load_index(path: str) -&gt; NumpyCosineIndex | BM25Index:\n    \"\"\"Load an index from disk.\"\"\"\n\n    with open(path, \"rb\") as f:\n        payload = msgpack.unpackb(f.read(), raw=False)\n    backend = payload.get(\"backend\")\n    if backend == \"bm25\":\n        return BM25Index.load(path)\n    if backend == \"numpy-cosine\":\n        return NumpyCosineIndex.load(path)\n    raise ValueError(f\"unknown index backend: {backend}\")\n</code></pre>"},{"location":"reference/python/#bijux_rag.rag.ports","title":"bijux_rag.rag.ports","text":"<p>RAG primitives: ports for embedders, indexes, retrieval, and generation.</p> <p>This module is deliberately dependency-light. Concrete backends live in sibling modules.</p> <p>The goal is to make bijux-rag actually RAG: ingest -&gt; index -&gt; retrieve (+ optional rerank) -&gt; answer with citations.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Answer","title":"Answer  <code>dataclass</code>","text":"<pre><code>Answer(text, citations=(), candidates=())\n</code></pre> <p>A grounded answer.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Answer text.</p> required <code>citations</code> <code>tuple[Citation, ...]</code> <p>Evidence citations.</p> <code>()</code>"},{"location":"reference/python/#bijux_rag.rag.ports.Candidate","title":"Candidate  <code>dataclass</code>","text":"<pre><code>Candidate(chunk, score, metadata=dict())\n</code></pre> <p>A retrieved chunk plus score and non-sensitive metadata.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Citation","title":"Citation  <code>dataclass</code>","text":"<pre><code>Citation(doc_id, chunk_id, start, end, text=None)\n</code></pre> <p>A citation referencing an evidence chunk.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Embedder","title":"Embedder","text":"<p>               Bases: <code>Protocol</code></p> <p>Embedder port.</p> <p>Implementations must be deterministic given the same inputs and configuration.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Generator","title":"Generator","text":"<p>               Bases: <code>Protocol</code></p> <p>Generator port.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Index","title":"Index","text":"<p>               Bases: <code>Protocol</code></p> <p>Index port.</p> <p>Indexes are responsible for persistence (save/load) and schema versioning.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Indexer","title":"Indexer","text":"<p>               Bases: <code>Protocol</code></p> <p>Indexer port.</p>"},{"location":"reference/python/#bijux_rag.rag.ports.Reranker","title":"Reranker","text":"<p>               Bases: <code>Protocol</code></p> <p>Reranker port.</p>"},{"location":"reference/python/#bijux_rag.boundaries.web.fastapi_app","title":"bijux_rag.boundaries.web.fastapi_app","text":"<p>FastAPI adapter exposing chunking and RAG endpoints.</p>"},{"location":"reference/python/#bijux_rag.boundaries.web.fastapi_app--pyright-reportunusedfunctionfalse","title":"pyright: reportUnusedFunction=false","text":""},{"location":"reference/python/#bijux_rag.boundaries.web.fastapi_app.create_app","title":"create_app","text":"<pre><code>create_app()\n</code></pre> <p>Construct a FastAPI app with chunking and RAG endpoints.</p> Source code in <code>src/bijux_rag/boundaries/web/fastapi_app.py</code> <pre><code>def create_app() -&gt; FastAPI:\n    \"\"\"Construct a FastAPI app with chunking and RAG endpoints.\"\"\"\n\n    app = FastAPI(title=\"bijux-rag\", openapi_version=\"3.1.0\")\n    router = APIRouter(prefix=\"/v1\")\n\n    _APP = RagApp()\n    _INDEX_STORE: Dict[str, RagIndex] = {}\n\n    @router.get(\"/healthz\")\n    async def healthz() -&gt; dict[str, bool]:\n        return {\"ok\": True}\n\n    @router.post(\"/chunks\", response_model=PChunkResponse)\n    async def chunks(req: PChunkRequest) -&gt; PChunkResponse:\n        # Boundary validation ensures we do not 500 on invalid inputs.\n        try:\n            docs = [(d.doc_id, d.text, d.title, d.category) for d in req.docs]\n            cfg = ChunkAndEmbedConfig(\n                chunk_size=req.chunk_size,\n                overlap=req.overlap,\n                include_embeddings=req.include_embeddings,\n            )\n            res = chunk_and_embed_docs(docs, cfg)\n        except ValueError as e:\n            # Defensive: should be unreachable if request validation is correct.\n            raise HTTPException(status_code=422, detail=str(e)) from e\n\n        if isinstance(res, Err):\n            raise HTTPException(status_code=400, detail=res.error)\n\n        return PChunkResponse(\n            chunks=[\n                ChunkOut(\n                    doc_id=c.doc_id,\n                    text=c.text,\n                    start=c.start,\n                    end=c.end,\n                    metadata=dict(c.metadata),\n                    embedding=c.embedding if c.embedding else None,\n                    chunk_id=c.chunk_id,\n                )\n                for c in res.value\n            ]\n        )\n\n    @router.post(\"/index/build\", response_model=IndexBuildResponse)\n    async def index_build(req: IndexBuildRequest) -&gt; IndexBuildResponse:\n        docs = [\n            RawDoc(\n                doc_id=d.doc_id,\n                title=d.title or \"\",\n                abstract=d.text,\n                categories=d.category or \"\",\n            )\n            for d in req.docs\n        ]\n        res = _APP.build_index(\n            docs=docs,\n            backend=_backend_from_str(req.backend),\n            chunk_size=req.chunk_size,\n            overlap=req.overlap,\n        )\n        if isinstance(res, Err):\n            raise HTTPException(status_code=400, detail=res.error)\n\n        idx = res.value\n        index_id = f\"idx_{idx.fingerprint}\"\n        _INDEX_STORE[index_id] = idx\n\n        return IndexBuildResponse(\n            index_id=index_id,\n            fingerprint=idx.fingerprint,\n            schema_version=idx.schema_version,\n        )\n\n    @router.post(\"/retrieve\", response_model=RetrieveResponse)\n    async def retrieve(req: RetrieveRequest) -&gt; RetrieveResponse:\n        idx = _INDEX_STORE.get(req.index_id)\n        if idx is None:\n            raise HTTPException(status_code=404, detail=\"Unknown index_id\")\n\n        res = _APP.retrieve(index=idx, query=req.query, top_k=req.top_k, filters=req.filters)\n        if isinstance(res, Err):\n            raise HTTPException(status_code=400, detail=res.error)\n\n        candidates: list[Candidate] = res.value\n        return RetrieveResponse(\n            candidates=[\n                PCandidate(\n                    score=c.score,\n                    chunk={\n                        \"doc_id\": c.chunk.doc_id,\n                        \"chunk_id\": c.chunk.chunk_id,\n                        \"text\": c.chunk.text,\n                        \"start\": c.chunk.start,\n                        \"end\": c.chunk.end,\n                        \"metadata\": dict(c.chunk.metadata),\n                    },\n                    metadata=dict(c.metadata),\n                )\n                for c in candidates\n            ]\n        )\n\n    @router.post(\"/ask\", response_model=AskResponse)\n    async def ask(req: AskRequest) -&gt; AskResponse:\n        idx = _INDEX_STORE.get(req.index_id)\n        if idx is None:\n            raise HTTPException(status_code=404, detail=\"Unknown index_id\")\n\n        res = _APP.ask(\n            index=idx,\n            query=req.query,\n            top_k=req.top_k,\n            filters=req.filters,\n            rerank=req.rerank,\n        )\n        if isinstance(res, Err):\n            raise HTTPException(status_code=400, detail=res.error)\n\n        ans = cast(Answer, res.value)\n        return AskResponse(\n            answer=ans.text,\n            citations=[\n                PCitation(\n                    doc_id=c.doc_id,\n                    chunk_id=c.chunk_id,\n                    start=c.start,\n                    end=c.end,\n                    text=c.text,\n                )\n                for c in ans.citations\n            ],\n            candidates=[\n                PCandidate(\n                    score=c.score,\n                    chunk={\n                        \"doc_id\": c.chunk.doc_id,\n                        \"chunk_id\": c.chunk.chunk_id,\n                        \"text\": c.chunk.text,\n                        \"start\": c.chunk.start,\n                        \"end\": c.chunk.end,\n                        \"metadata\": dict(c.chunk.metadata),\n                    },\n                    metadata=dict(c.metadata),\n                )\n                for c in ans.candidates\n            ],\n        )\n\n    app.include_router(router)\n\n    def _custom_openapi() -&gt; dict[str, Any]:\n        if app.openapi_schema:\n            return app.openapi_schema\n        app.openapi_schema = get_openapi(\n            title=app.title,\n            version=\"0.1.0\",\n            routes=app.routes,\n            openapi_version=\"3.1.0\",\n            description=app.description,\n        )\n        return app.openapi_schema\n\n    app.openapi = _custom_openapi  # type: ignore[method-assign]\n    return app\n</code></pre>"}]}